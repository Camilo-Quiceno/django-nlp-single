{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npip install transformers\\npip install tensorflow\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pip install transformers\n",
    "pip install tensorflow\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Camilo Quinceno\\Documents\\Entrenamiento\\personal-proyects\\django-nlp-single\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumarizer\n",
    "\n",
    "The input to this task is a corpus of text and the model will output a summary of it based on the expected length mentioned in the parameters. Here, we have kept minimum length as 5 and maximum length as 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "c:\\Users\\Camilo Quinceno\\Documents\\Entrenamiento\\personal-proyects\\django-nlp-single\\venv\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\n",
    "    \"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text summarize is : 1980s action thriller starring Tom Cruise is chock full of chases and battles . there are also violent and upsetting scenes,\n"
     ]
    }
   ],
   "source": [
    "input = \"Parents need to know that Top Gun is a blockbuster 1980s action thriller starring Tom Cruise that's chock full of narrow escapes, chases, and battles. But there are also violent and upsetting scenes, particularly the death of a main character, which make it too intense for younger kids. There's also one graphic-for-its-time sex scene (though no explicit nudity) and quite a few shirtless men in locker rooms and, in one iconic sequence, on a beach volleyball court. Winning is the most important thing to all the pilots, who try to intimidate one another with plenty of posturing and banter -- though when push comes to shove, loyalty and friendship have important roles to play, too. While sexism is noticeable and almost all characters are men, two strong women help keep some of the objectification in check.\"\n",
    "output_summarizer = summarizer(input, min_length=5, max_length=30)[0]['summary_text']\n",
    "print(f'The text summarize is: {output_summarizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering\n",
    "\n",
    "In this task, we provide a question and a context. The model will choose the answer from the context based on the highest probability score. It also provides the starting and ending positions of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering = pipeline(model=\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer of the question is: University of Montreal with a score of: 0.6422632336616516\n"
     ]
    }
   ],
   "source": [
    "output_question_answering = question_answering(\n",
    "                                question=\"Where do I work?\",\n",
    "                                context=\"I work as a Data Scientist at a lab in University of Montreal. I like to develop my own algorithms.\",\n",
    "                            )\n",
    "answer_qa = output_question_answering['answer']\n",
    "score_qa = output_question_answering['score']\n",
    "print(f'The answer of the question is: {answer_qa} with a score of: {score_qa}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Entity Recognition\n",
    "\n",
    "Named Entity Recognition deals with identifying and classifying the words based on the names of persons, organizations, locations and so on. The input is basically a sentence and the model will determine the named entity along with its category and its corresponding location in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.26k/1.26k [00:00<00:00, 1.26MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 438M/438M [00:12<00:00, 34.0MB/s] \n",
      "Some weights of the model checkpoint at dslim/bert-base-NER-uncased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 39.0/39.0 [00:00<00:00, 39.1kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.66MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "entity_classifier = pipeline(\n",
    "    model=\"dslim/bert-base-NER-uncased\", aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entity group of the word john is PER \n",
      "The entity group of the word jane is PER \n",
      "The entity group of the word spain is LOC \n"
     ]
    }
   ],
   "source": [
    "sentence = \"John and Jane like to travel around Spain by train.\"\n",
    "entities = entity_classifier(sentence)\n",
    "for entity in entities:\n",
    "        entity_group = entity['entity_group']\n",
    "        word = entity['word']\n",
    "        print(f'The entity group of the word {word} is {entity_group} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging \n",
    "PoS Tagging is useful to classify the text and provide its relevant parts of speech such as whether a word is a noun, pronoun, verb and so on. The model returns PoS tagged words along with their probability scores and respective locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.06k/1.06k [00:00<?, ?B/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:22<00:00, 19.9MB/s] \n",
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<?, ?B/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.73MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "pos_tagger = pipeline(\n",
    "    model=\"vblagoje/bert-english-uncased-finetuned-pos\",\n",
    "    aggregation_strategy=\"simple\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entity group of the word i is PRON \n",
      "The entity group of the word am is AUX \n",
      "The entity group of the word an is DET \n",
      "The entity group of the word artist is NOUN \n",
      "The entity group of the word and is CCONJ \n",
      "The entity group of the word i is PRON \n",
      "The entity group of the word live is VERB \n",
      "The entity group of the word in is ADP \n",
      "The entity group of the word dublin is PROPN \n"
     ]
    }
   ],
   "source": [
    "taggings = pos_tagger(\"I am an artist and I live in Dublin\")\n",
    "for tagging in taggings:\n",
    "        entity_group = tagging['entity_group']\n",
    "        word = tagging['word']\n",
    "        print(f'The entity group of the word {word} is {entity_group} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analizer\n",
    "We will perform sentiment analysis and classify the text based on the tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "text_classifier = pipeline(\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is classified as: Positive with a score of 0.9997908473014832\n"
     ]
    }
   ],
   "source": [
    "output_classifier = text_classifier(\"This movie is my favorite!\")\n",
    "label_classfier = output_classifier[0]['label']\n",
    "score_classifier = output_classifier[0]['score']\n",
    "print(f'The text is classified as: {label_classfier.capitalize()} with a score of {score_classifier}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<?, ?B/s] \n",
      "Downloading model.safetensors: 100%|██████████| 548M/548M [00:15<00:00, 34.3MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<?, ?B/s] \n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 8.39MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 11.8MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.83MB/s]\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "c:\\Users\\Camilo Quinceno\\Documents\\Entrenamiento\\personal-proyects\\django-nlp-single\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1369: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text generated is: If it is sunny today then  it will be cloudy tomorrow.\n",
      "I have been using this for a while now and I am very happy with it. I have been using it for a while now and I am very happy with it. I\n"
     ]
    }
   ],
   "source": [
    "generated_text = text_generator(\"If it is sunny today then \", do_sample=False)[0]['generated_text']\n",
    "print(f'The text generated is: {generated_text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Translation\n",
    "Here, we will translate the language of text from one language to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 1.20MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 242M/242M [00:07<00:00, 32.1MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 147kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 2.32k/2.32k [00:00<?, ?B/s]\n",
      "Downloading (…)ve/main/spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 5.98MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.39M/1.39M [00:00<00:00, 13.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "en_fr_translator = pipeline(\"translation_en_to_fr\", model='t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text translated is Bonjour, Comment êtes-vous ?\n"
     ]
    }
   ],
   "source": [
    "output_translator = en_fr_translator(\"Hi, How are you?\")\n",
    "text_translated = output_translator[0]['translation_text']\n",
    "print(f'The text translated is: {text_translated}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
